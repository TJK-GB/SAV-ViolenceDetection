{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"127JTfHnIjpZnZ56zICjHwLj8voVlY5T1","authorship_tag":"ABX9TyMyOXFkeTWxEaQmsN1aDWbb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNAPmNckHao1","executionInfo":{"status":"ok","timestamp":1755126935214,"user_tz":-60,"elapsed":4945913,"user":{"displayName":"Taejin Kim","userId":"03444209368555110847"}},"outputId":"c7e805c7-da49-4f28-e9d8-eb541012586f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10: 100%|██████████| 168/168 [16:44<00:00,  5.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 110.0561 | Macro F1: 0.4827 | Micro F1: 0.5874\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 168/168 [06:25<00:00,  2.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 97.7987 | Macro F1: 0.6766 | Micro F1: 0.6831\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 168/168 [06:11<00:00,  2.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 88.2912 | Macro F1: 0.7074 | Micro F1: 0.7145\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 168/168 [06:07<00:00,  2.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 81.0329 | Macro F1: 0.7571 | Micro F1: 0.7608\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 168/168 [06:05<00:00,  2.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 74.7712 | Macro F1: 0.7697 | Micro F1: 0.7728\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 168/168 [06:04<00:00,  2.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 | Loss: 72.3450 | Macro F1: 0.7754 | Micro F1: 0.7773\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 168/168 [06:06<00:00,  2.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 | Loss: 63.7738 | Macro F1: 0.8230 | Micro F1: 0.8266\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 168/168 [06:02<00:00,  2.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 | Loss: 59.0119 | Macro F1: 0.8380 | Micro F1: 0.8401\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 168/168 [06:02<00:00,  2.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 | Loss: 59.5529 | Macro F1: 0.8487 | Micro F1: 0.8505\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 168/168 [06:00<00:00,  2.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 | Loss: 47.1004 | Macro F1: 0.8652 | Micro F1: 0.8670\n","\n","[TEST] BCE Loss: 0.6741\n","[TEST] Macro F1: 0.6921\n","[TEST] Micro F1: 0.7055\n","[TEST] Per-Class F1 Scores:\n"," - Non-violent F1: 0.7563\n"," - Violent F1: 0.6279\n","Confusion Matrix:\n"," [[149  34]\n"," [ 62  81]]\n"]}],"source":["import os, random, numpy as np, pandas as pd\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision import transforms\n","from torch.amp import autocast, GradScaler\n","\n","# === REPRODUCIBILITY ===\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# === PATHS ===\n","train_csv_path = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/train.csv\"\n","test_csv_path  = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/test.csv\"\n","NPY_DIR  = \"/content/drive/MyDrive/Colab Notebooks/Projects/npy_segments_unimodal\"\n","save_path = \"/content/drive/MyDrive/Colab Notebooks/Results/Unfrozen_randomseed/ResNet50+GRU\"\n","os.makedirs(save_path, exist_ok=True)\n","\n","# === CONFIG ===\n","BATCH_SIZE = 4\n","GRAD_ACCUM_STEPS = 4\n","EPOCHS = 10\n","MAX_FRAMES = 80\n","EARLY_STOPPING_PATIENCE = 4\n","\n","# === MODEL ===\n","class ResNet50GRU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n","        self.resnet.fc = nn.Identity()  # fully unfrozen\n","        self.gru = nn.GRU(2048, 256, batch_first=True, bidirectional=True)\n","        self.dropout = nn.Dropout(0.3)\n","        self.attn = nn.Linear(512, 1)\n","        self.fc = nn.Linear(512, 1)\n","\n","    def forward(self, x):\n","        B, T, C, H, W = x.size()\n","        x = x.view(B*T, C, H, W)\n","        feats = self.resnet(x).view(B, T, -1)\n","        out, _ = self.gru(feats)\n","        weights = torch.softmax(self.attn(out), dim=1)\n","        out = torch.sum(weights * out, dim=1)\n","        out = self.dropout(out)\n","        return self.fc(out).squeeze(1)\n","\n","# === DATASET ===\n","class ViolenceDataset(Dataset):\n","    def __init__(self, csv_path, npy_dir):\n","        self.df = pd.read_csv(csv_path)\n","        self.npy_dir = npy_dir\n","        self.transform = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.Resize((224, 224)),\n","            transforms.RandomHorizontalFlip(0.5),\n","            transforms.ColorJitter(0.2, 0.2),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n","        ])\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        frames = np.load(os.path.join(self.npy_dir, f\"{row['Segment ID']}.npy\"))[:MAX_FRAMES]\n","        frames = torch.stack([self.transform(torch.from_numpy(f).permute(2,0,1).float()/255.0) for f in frames])\n","        return frames, torch.tensor(row['Violence label(video)'], dtype=torch.float32)\n","\n","# === INIT ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_dataset = ViolenceDataset(train_csv_path, NPY_DIR)\n","test_dataset  = ViolenceDataset(test_csv_path,  NPY_DIR)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n","\n","model = ResNet50GRU().to(device)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n","scaler = GradScaler()\n","\n","best_loss, early_stop_counter = float('inf'), 0\n","\n","# === TRAIN ===\n","for epoch in range(EPOCHS):\n","    model.train()\n","    y_true, y_pred, total_loss = [], [], 0.0\n","    optimizer.zero_grad()\n","    for i, (frames, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")):\n","        frames, labels = frames.to(device), labels.to(device)\n","        with autocast(device_type='cuda'):\n","            outputs = model(frames)\n","            loss = criterion(outputs, labels) / GRAD_ACCUM_STEPS\n","        scaler.scale(loss).backward()\n","        if (i+1) % GRAD_ACCUM_STEPS == 0 or (i+1) == len(train_loader):\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","        total_loss += loss.item() * GRAD_ACCUM_STEPS\n","        preds = (torch.sigmoid(outputs) > 0.5).int()\n","        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n","    macro_f1 = f1_score(y_true, y_pred, average='macro')\n","    micro_f1 = f1_score(y_true, y_pred, average='micro')\n","    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Macro F1: {macro_f1:.4f} | Micro F1: {micro_f1:.4f}\")\n","    scheduler.step(total_loss)\n","    if total_loss < best_loss:\n","        best_loss = total_loss\n","        torch.save(model.state_dict(), os.path.join(save_path, \"resnet50_gru_best.pt\"))\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= EARLY_STOPPING_PATIENCE: break\n","\n","# === TEST ===\n","model.load_state_dict(torch.load(os.path.join(save_path, \"resnet50_gru_best.pt\")))\n","model.eval()\n","y_true, y_pred, test_losses = [], [], []\n","segment_ids = test_dataset.df['Segment ID'].tolist()\n","with torch.no_grad():\n","    for frames, labels in test_loader:\n","        frames, labels = frames.to(device), labels.to(device)\n","        outputs = model(frames)\n","        loss = criterion(outputs, labels)\n","        test_losses.append(loss.item())\n","        preds = (torch.sigmoid(outputs) > 0.5).int()\n","        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n","\n","avg_test_loss = np.mean(test_losses)\n","report = classification_report(y_true, y_pred, target_names=[\"Non-violent\",\"Violent\"], output_dict=True, zero_division=0)\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","print(f\"\\n[TEST] BCE Loss: {avg_test_loss:.4f}\")\n","print(f\"[TEST] Macro F1: {report['macro avg']['f1-score']:.4f}\")\n","print(f\"[TEST] Micro F1: {f1_score(y_true,y_pred,average='micro'):.4f}\")\n","print(\"[TEST] Per-Class F1 Scores:\")\n","print(f\" - Non-violent F1: {report['Non-violent']['f1-score']:.4f}\")\n","print(f\" - Violent F1: {report['Violent']['f1-score']:.4f}\")\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","\n","pd.DataFrame({\"Segment ID\": segment_ids, \"True\": y_true, \"Pred\": y_pred}).to_csv(\n","    os.path.join(save_path, \"resnet50_gru_predictions.csv\"), index=False)\n","pd.DataFrame(report).to_csv(os.path.join(save_path, \"resnet50_gru_test_metrics.csv\"))\n"]}]}
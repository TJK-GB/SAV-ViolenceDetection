{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVYfHGehAavy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1706169,
     "status": "ok",
     "timestamp": 1754664695868,
     "user": {
      "displayName": "Taejin Kim",
      "userId": "03444209368555110847"
     },
     "user_tz": -60
    },
    "id": "6Ai8eksNTjVx",
    "outputId": "9c2be0f9-19db-4c1f-e5f1-81a3464277c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 285/326 [25:07<09:38, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] 271_2: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-jwXG9OABYnsPLwBFf44af35b on tokens per min (TPM): Limit 30000, Used 30000, Requested 7734. Please try again in 15.467s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 316/326 [27:37<01:22,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] 283_5: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-jwXG9OABYnsPLwBFf44af35b on tokens per min (TPM): Limit 30000, Used 30000, Requested 7734. Please try again in 15.467s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 326/326 [28:25<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved predictions to: /content/drive/MyDrive/Colab Notebooks/Projects/results/LLM Results/gpt4o_segment_predictions.csv\n",
      "\n",
      " Confusion Matrix:\n",
      "[[155  27]\n",
      " [ 66  76]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-violent       0.70      0.85      0.77       182\n",
      "     Violent       0.74      0.54      0.62       142\n",
      "\n",
      "    accuracy                           0.71       324\n",
      "   macro avg       0.72      0.69      0.69       324\n",
      "weighted avg       0.72      0.71      0.70       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuration set-up\n",
    "API_KEY = \"\" # API here\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "# Paths\n",
    "CSV_PATH = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/test.csv\"\n",
    "NPY_DIR = \"/content/drive/MyDrive/Colab Notebooks/Projects/npy_segments_unimodal\"\n",
    "SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/Projects/results/LLM Results\"\n",
    "SAVE_NAME = \"gpt4o_segment_predictions.csv\"\n",
    "NUM_FRAMES = 10\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Image encoding function\n",
    "def encode_frame_to_base64(frame):\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "    if frame.ndim == 2 or frame.shape[-1] != 3:\n",
    "        frame = np.stack([frame] * 3, axis=-1)\n",
    "    img = Image.fromarray(frame).resize(IMAGE_SIZE)\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    img_bytes = buffered.getvalue()\n",
    "    encoded = b64encode(img_bytes).decode(\"utf-8\")\n",
    "    return {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/png;base64,{encoded}\"}\n",
    "    }\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"Segment ID\"] = df[\"Segment ID\"].astype(str)\n",
    "results = []\n",
    "\n",
    "# Process each segment\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    segment_id = row[\"Segment ID\"]\n",
    "    true_label = int(row[\"Violence label(video)\"]) if \"Violence label(video)\" in row else int(row[\"Violence label\"])\n",
    "    npy_path = os.path.join(NPY_DIR, f\"{segment_id}.npy\")\n",
    "\n",
    "    if not os.path.exists(npy_path):\n",
    "        print(f\"[Missing] {segment_id}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        frames = np.load(npy_path)\n",
    "        total_frames = len(frames)\n",
    "        indices = np.linspace(0, total_frames - 1, min(total_frames, NUM_FRAMES), dtype=int)\n",
    "        sampled_frames = frames[indices]\n",
    "\n",
    "        encoded_images = [encode_frame_to_base64(f) for f in sampled_frames]\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a video analysis assistant. Given several frames from a video segment, determine whether any violence occurs. If yes, list the frame numbers where it happens.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    *encoded_images,\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"These are frames from a short surveillance video segment. Is there any violent action? If so, which frames (e.g. 1, 4, 8) show violence? If none, say 'None'.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.2,\n",
    "            max_tokens=200\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message.content\n",
    "        gpt_pred_label = 1 if \"frame\" in reply.lower() or \"yes\" in reply.lower() else 0\n",
    "\n",
    "        results.append({\n",
    "            \"segment_id\": segment_id,\n",
    "            \"gpt_pred_label\": gpt_pred_label,\n",
    "            \"true_label\": true_label,\n",
    "            \"gpt_response\": reply\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {segment_id}: {e}\")\n",
    "        results.append({\n",
    "            \"segment_id\": segment_id,\n",
    "            \"gpt_pred_label\": \"error\",\n",
    "            \"true_label\": true_label,\n",
    "            \"gpt_response\": str(e)\n",
    "        })\n",
    "\n",
    "# Save results\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "df_out = pd.DataFrame(results)\n",
    "save_path = os.path.join(SAVE_DIR, SAVE_NAME)\n",
    "df_out.to_csv(save_path, index=False)\n",
    "print(f\"\\n Saved predictions to: {save_path}\")\n",
    "\n",
    "# Evaluate predictions\n",
    "df_valid = df_out[df_out[\"gpt_pred_label\"] != \"error\"].copy()\n",
    "df_valid[\"gpt_pred_label\"] = df_valid[\"gpt_pred_label\"].astype(int)\n",
    "df_valid[\"true_label\"] = df_valid[\"true_label\"].astype(int)\n",
    "\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(df_valid[\"true_label\"], df_valid[\"gpt_pred_label\"]))\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(df_valid[\"true_label\"], df_valid[\"gpt_pred_label\"], target_names=[\"Non-violent\", \"Violent\"]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPeQIHcwTSy5ze0hkZMy2zv",
   "gpuType": "L4",
   "machine_shape": "hm",
   "mount_file_id": "1F224r_GwFXsbsHl1sHj1wfU8UE7eJh8z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

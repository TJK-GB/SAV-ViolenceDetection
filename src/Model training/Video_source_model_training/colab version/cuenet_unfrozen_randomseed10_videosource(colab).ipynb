{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9213423,
     "status": "ok",
     "timestamp": 1755259153477,
     "user": {
      "displayName": "Taejin Kim",
      "userId": "03444209368555110847"
     },
     "user_tz": -60
    },
    "id": "24ooGEVJNTVk",
    "outputId": "7bbe0410-7305-4e0f-8cdf-824199f435cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 1/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|██████████| 168/168 [28:22<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.7920 | Macro F1: 0.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 2/10: 100%|██████████| 168/168 [12:46<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.7941 | Macro F1: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 3/10: 100%|██████████| 168/168 [12:31<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.7915 | Macro F1: 0.4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 4/10: 100%|██████████| 168/168 [13:40<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.7907 | Macro F1: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 5/10: 100%|██████████| 168/168 [12:33<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.7896 | Macro F1: 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 6/10: 100%|██████████| 168/168 [11:55<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.7878 | Macro F1: 0.5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 7/10: 100%|██████████| 168/168 [12:53<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.7859 | Macro F1: 0.5165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 8/10: 100%|██████████| 168/168 [11:27<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.7888 | Macro F1: 0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 9/10: 100%|██████████| 168/168 [12:08<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.7859 | Macro F1: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   0%|          | 0/168 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 10/10: 100%|██████████| 168/168 [13:29<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.7833 | Macro F1: 0.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] BCE Loss: 0.7994\n",
      "[TEST] Macro F1: 0.4439\n",
      "[TEST] Micro F1: 0.4448\n",
      "[TEST] Per-Class F1 Scores:\n",
      " - Non-violent F1: 0.4661\n",
      " - Violent F1: 0.4217\n",
      "Confusion Matrix:\n",
      " [[ 79 104]\n",
      " [ 77  66]]\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#  PATHS change to your directory\n",
    "train_csv_path = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/video_source/train.csv\"\n",
    "test_csv_path  = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/video_source/test.csv\"\n",
    "NPY_DIR        = \"/content/drive/MyDrive/Colab Notebooks/npy_segments_videosource\"\n",
    "save_path      = \"/content/drive/MyDrive/Colab Notebooks/Results/Unfrozen_randomseed/Video-source/CUE-NET\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 4\n",
    "MAX_FRAMES = 80\n",
    "EPOCHS = 10\n",
    "USE_WEIGHTED_LOSS = True\n",
    "NUM_SRC_CLASSES = 7\n",
    "\n",
    "# CUE-Net Model\n",
    "class CUEBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv3d = nn.Conv3d(in_ch, out_ch, kernel_size=(3,3,3), padding=1)\n",
    "        self.bn = nn.BatchNorm3d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        def _f(inp):\n",
    "            return self.relu(self.bn(self.conv3d(inp)))\n",
    "        return checkpoint(_f, x)\n",
    "\n",
    "class CUENetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc1 = CUEBlock(3, 32)\n",
    "        self.enc2 = CUEBlock(32, 64)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.fc = nn.Linear(64 + NUM_SRC_CLASSES, 1)\n",
    "\n",
    "    def forward(self, x, src_onehot):\n",
    "        x = x.permute(0, 2, 1, 3, 4)  # B,C,T,H,W\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        fused = torch.cat([x, src_onehot], dim=1)\n",
    "        return self.fc(fused).squeeze(1)\n",
    "\n",
    "# Dataset load\n",
    "class ViolenceDataset(Dataset):\n",
    "    def __init__(self, csv_path, npy_dir):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.npy_dir = npy_dir\n",
    "        self.resize = Resize((224, 224))\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        frames = np.load(os.path.join(self.npy_dir, f\"{row['Segment ID']}.npy\"))\n",
    "        frames = [torch.from_numpy(f).permute(2,0,1).float()/255.0 for f in frames]\n",
    "        frames = [self.resize(f) for f in frames]\n",
    "        if len(frames) < MAX_FRAMES:\n",
    "            pad_frame = torch.zeros_like(frames[0])\n",
    "            frames += [pad_frame] * (MAX_FRAMES - len(frames))\n",
    "        frames = torch.stack(frames[:MAX_FRAMES])\n",
    "\n",
    "        src_label = torch.tensor(row['Video Source Label'], dtype=torch.long)\n",
    "        src_onehot = torch.nn.functional.one_hot(src_label, num_classes=NUM_SRC_CLASSES).float()\n",
    "        return frames, torch.tensor(row['Violence label(video)'], dtype=torch.float32), src_onehot\n",
    "\n",
    "# actual training configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataset = ViolenceDataset(train_csv_path, NPY_DIR)\n",
    "test_dataset  = ViolenceDataset(test_csv_path,  NPY_DIR)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "pos = train_dataset.df['Violence label(video)'].sum()\n",
    "neg = len(train_dataset) - pos\n",
    "ratio = neg / max(pos, 1)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([ratio]).to(device)) if USE_WEIGHTED_LOSS else nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = CUENetClassifier().to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# train\n",
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    y_true, y_pred, total_loss = [], [], 0.0\n",
    "    for frames, labels, src_onehot in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        frames, labels, src_onehot = frames.to(device), labels.to(device), src_onehot.to(device)\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(frames, src_onehot)\n",
    "            loss = criterion(outputs, labels)\n",
    "        optimiser.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimiser)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Macro F1: {macro_f1:.4f}\")\n",
    "    if macro_f1 > best_f1:\n",
    "        best_f1 = macro_f1\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"cuenet_best.pt\"))\n",
    "\n",
    "# test\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, \"cuenet_best.pt\")))\n",
    "model.eval()\n",
    "y_true, y_pred, test_losses = [], [], []\n",
    "segment_ids = test_dataset.df['Segment ID'].tolist()\n",
    "with torch.no_grad():\n",
    "    for frames, labels, src_onehot in test_loader:\n",
    "        frames, labels, src_onehot = frames.to(device), labels.to(device), src_onehot.to(device)\n",
    "        outputs = model(frames, src_onehot)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_losses.append(loss.item())\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Non-violent\",\"Violent\"], output_dict=True, zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n[TEST] BCE Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"[TEST] Macro F1: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"[TEST] Micro F1: {f1_score(y_true,y_pred,average='micro'):.4f}\")\n",
    "print(\"[TEST] Per-Class F1 Scores:\")\n",
    "print(f\" - Non-violent F1: {report['Non-violent']['f1-score']:.4f}\")\n",
    "print(f\" - Violent F1: {report['Violent']['f1-score']:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "pd.DataFrame({\"Segment ID\": segment_ids, \"True\": y_true, \"Pred\": y_pred}).to_csv(\n",
    "    os.path.join(save_path, \"cuenet_predictions.csv\"), index=False)\n",
    "pd.DataFrame(report).to_csv(os.path.join(save_path, \"cuenet_test_metrics.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPh0y/b53pJec3Pz+58jJ0O",
   "gpuType": "L4",
   "machine_shape": "hm",
   "mount_file_id": "1BbGo6P3mcqn1n2DtiGm5kxRKf559qLEH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

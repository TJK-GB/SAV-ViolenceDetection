{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1nqrBZwsyZMJwK25AkD5YYsBraGXhDnUs","authorship_tag":"ABX9TyMlKpQtgRBufXESPi4Y9GEt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzzrhFLkYwa1","outputId":"9474a425-e164-44bb-e4af-637387cac785","executionInfo":{"status":"ok","timestamp":1755280099042,"user_tz":-60,"elapsed":8468077,"user":{"displayName":"Taejin Kim","userId":"03444209368555110847"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n","100%|██████████| 108M/108M [00:00<00:00, 199MB/s] \n","Epoch 1/10: 100%|██████████| 168/168 [23:41<00:00,  8.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 0.8233 | Macro F1: 0.4955\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 168/168 [13:00<00:00,  4.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 0.7811 | Macro F1: 0.5698\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 168/168 [11:33<00:00,  4.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 0.7695 | Macro F1: 0.5648\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 168/168 [11:00<00:00,  3.93s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 0.7669 | Macro F1: 0.5686\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 168/168 [12:26<00:00,  4.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 0.7500 | Macro F1: 0.6018\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 168/168 [10:59<00:00,  3.93s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 | Loss: 0.7600 | Macro F1: 0.6063\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 168/168 [12:51<00:00,  4.60s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 | Loss: 0.7396 | Macro F1: 0.6082\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 168/168 [11:42<00:00,  4.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 | Loss: 0.7109 | Macro F1: 0.6218\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 168/168 [11:25<00:00,  4.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 | Loss: 0.7227 | Macro F1: 0.6286\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 168/168 [11:19<00:00,  4.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 | Loss: 0.6781 | Macro F1: 0.6730\n","\n","[TEST] BCE Loss: 0.8391\n","[TEST] Macro F1: 0.4706\n","[TEST] Micro F1: 0.4785\n","[TEST] Per-Class F1 Scores:\n"," - Non-violent F1: 0.4056\n"," - Violent F1: 0.5355\n","Confusion Matrix:\n"," [[ 58 125]\n"," [ 45  98]]\n"]}],"source":["import os, random, numpy as np, pandas as pd\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models import swin_t, Swin_T_Weights\n","from torchvision.transforms import Resize\n","from torch.amp import autocast, GradScaler\n","\n","# === REPRODUCIBILITY ===\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# === PATHS ===\n","train_csv_path = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/video_source/train.csv\"\n","test_csv_path  = \"/content/drive/MyDrive/Colab Notebooks/Projects/CSVs/video_source/test.csv\"\n","NPY_DIR        = \"/content/drive/MyDrive/Colab Notebooks/npy_segments_videosource\"\n","save_path      = \"/content/drive/MyDrive/Colab Notebooks/Results/Unfrozen_randomseed/Video-source/Swin+GRU\"\n","os.makedirs(save_path, exist_ok=True)\n","\n","# === CONFIG ===\n","BATCH_SIZE = 4\n","MAX_FRAMES = 80\n","EPOCHS = 10\n","USE_WEIGHTED_LOSS = True\n","NUM_SRC_CLASSES = 7  # CCTV, News, Self-filmed, Dashcam, Combinations, Others, Bodycam\n","\n","# === MODEL ===\n","class SwinGRUClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.swin = swin_t(weights=Swin_T_Weights.DEFAULT)\n","        self.swin.head = nn.Identity()  # remove classification head\n","        self.gru = nn.GRU(input_size=768 + NUM_SRC_CLASSES, hidden_size=256,\n","                          num_layers=1, bidirectional=True, batch_first=True)\n","        self.fc = nn.Linear(256 * 2, 1)\n","\n","    def forward(self, x, src_onehot):\n","        B, T, C, H, W = x.shape\n","        x = x.view(B * T, C, H, W)\n","        features = self.swin(x).view(B, T, -1)\n","        src_feat = src_onehot.unsqueeze(1).repeat(1, T, 1)\n","        fused = torch.cat([features, src_feat], dim=2)\n","        out, _ = self.gru(fused)\n","        pooled = out.mean(dim=1)\n","        return self.fc(pooled).squeeze(1)\n","\n","# === DATASET ===\n","class ViolenceDataset(Dataset):\n","    def __init__(self, csv_path, npy_dir):\n","        self.df = pd.read_csv(csv_path)\n","        self.npy_dir = npy_dir\n","        self.resize = Resize((224, 224))\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        frames = np.load(os.path.join(self.npy_dir, f\"{row['Segment ID']}.npy\"))\n","        frames = [torch.from_numpy(f).permute(2,0,1).float()/255.0 for f in frames]\n","        frames = [self.resize(f) for f in frames]\n","\n","        # pad/truncate to MAX_FRAMES\n","        if len(frames) < MAX_FRAMES:\n","            pad_frame = torch.zeros_like(frames[0])\n","            frames += [pad_frame] * (MAX_FRAMES - len(frames))\n","        frames = torch.stack(frames[:MAX_FRAMES])\n","\n","        src_label = torch.tensor(row['Video Source Label'], dtype=torch.long)\n","        src_onehot = torch.nn.functional.one_hot(src_label, num_classes=NUM_SRC_CLASSES).float()\n","\n","        return frames, torch.tensor(row['Violence label(video)'], dtype=torch.float32), src_onehot\n","\n","# === INIT ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_dataset = ViolenceDataset(train_csv_path, NPY_DIR)\n","test_dataset  = ViolenceDataset(test_csv_path,  NPY_DIR)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n","\n","pos = train_dataset.df['Violence label(video)'].sum()\n","neg = len(train_dataset) - pos\n","ratio = neg / max(pos, 1)\n","criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([ratio]).to(device)) if USE_WEIGHTED_LOSS else nn.BCEWithLogitsLoss()\n","\n","model = SwinGRUClassifier().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","scaler = GradScaler()\n","\n","# === TRAIN ===\n","best_f1 = 0\n","for epoch in range(EPOCHS):\n","    model.train()\n","    y_true, y_pred, total_loss = [], [], 0.0\n","    for frames, labels, src_onehot in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n","        frames, labels, src_onehot = frames.to(device), labels.to(device), src_onehot.to(device)\n","        with autocast(device_type='cuda'):\n","            outputs = model(frames, src_onehot)\n","            loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        total_loss += loss.item()\n","        preds = (torch.sigmoid(outputs) > 0.5).int()\n","        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n","    macro_f1 = f1_score(y_true, y_pred, average='macro')\n","    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Macro F1: {macro_f1:.4f}\")\n","    if macro_f1 > best_f1:\n","        best_f1 = macro_f1\n","        torch.save(model.state_dict(), os.path.join(save_path, \"swin_gru_best.pt\"))\n","\n","# === TEST ===\n","model.load_state_dict(torch.load(os.path.join(save_path, \"swin_gru_best.pt\")))\n","model.eval()\n","y_true, y_pred, test_losses = [], [], []\n","segment_ids = test_dataset.df['Segment ID'].tolist()\n","with torch.no_grad():\n","    for frames, labels, src_onehot in test_loader:\n","        frames, labels, src_onehot = frames.to(device), labels.to(device), src_onehot.to(device)\n","        outputs = model(frames, src_onehot)\n","        loss = criterion(outputs, labels)\n","        test_losses.append(loss.item())\n","        preds = (torch.sigmoid(outputs) > 0.5).int()\n","        y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n","\n","avg_test_loss = np.mean(test_losses)\n","report = classification_report(y_true, y_pred, target_names=[\"Non-violent\",\"Violent\"], output_dict=True, zero_division=0)\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","print(f\"\\n[TEST] BCE Loss: {avg_test_loss:.4f}\")\n","print(f\"[TEST] Macro F1: {report['macro avg']['f1-score']:.4f}\")\n","print(f\"[TEST] Micro F1: {f1_score(y_true,y_pred,average='micro'):.4f}\")\n","print(\"[TEST] Per-Class F1 Scores:\")\n","print(f\" - Non-violent F1: {report['Non-violent']['f1-score']:.4f}\")\n","print(f\" - Violent F1: {report['Violent']['f1-score']:.4f}\")\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","\n","pd.DataFrame({\"Segment ID\": segment_ids, \"True\": y_true, \"Pred\": y_pred}).to_csv(\n","    os.path.join(save_path, \"swin_gru_predictions.csv\"), index=False)\n","pd.DataFrame(report).to_csv(os.path.join(save_path, \"swin_gru_test_metrics.csv\"))\n"]}]}
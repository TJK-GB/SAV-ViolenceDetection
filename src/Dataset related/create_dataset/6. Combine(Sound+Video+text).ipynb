{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd62e15-5ac5-43ce-b27d-ad689e7050ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "BASE_PATH = r\"D:\\UK\\00. 2024 QMUL\\00. Course\\SAV-ViolenceDetection\\Annotations_Final\\test\"\n",
    "\n",
    "FRAME_ANNOTATION_PATH = os.path.join(BASE_PATH, \"use_annotation_(framelevel_refinement).xlsx\")\n",
    "SOUND_ANNOTATION_PATH = os.path.join(BASE_PATH, \"use_annotation(sound_time unit)_ver2.xlsx\")\n",
    "\n",
    "file_1 = pd.read_excel(FRAME_ANNOTATION_PATH)\n",
    "file_2 = pd.read_excel(SOUND_ANNOTATION_PATH)\n",
    "video_df = pd.DataFrame(file_1)\n",
    "sound_df = pd.DataFrame(file_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9c5cd0-29e6-43f2-9338-cabca0ddf2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_df = sound_df.rename(columns={\n",
    "    'Start frame' : 'Start frame(sound)',\n",
    "    'End frame' : 'End frame(sound)',\n",
    "    'Sound Type' : 'sound_label'\n",
    "    })\n",
    "\n",
    "video_df = video_df.rename(columns={\n",
    "    'Start Frame' : 'Start frame',\n",
    "    'End Frame' : 'End frame',\n",
    "    'Violence Type (Sound)' : 'Violence(Sound) Type',\n",
    "    'Start Time (s)' : 'Start time(s)',\n",
    "    'End Time (s)' : 'End time(s)'\n",
    "})\n",
    "\n",
    "sound_df_refined = sound_df.drop(columns =[\n",
    "                                 'Filename',\n",
    "                                 'Duplicated moment with previous',\n",
    "                                 'Sound Start',\n",
    "                                 'Sound End',\n",
    "                                 'Max frame',\n",
    "                                 'Max Time'])\n",
    "\n",
    "video_df_refined = video_df.astype(\n",
    "    {'Video ID': int,\n",
    "     'Start frame':float,\n",
    "     'End frame':float}\n",
    "     )\n",
    "\n",
    "sound_df_refined = sound_df_refined.astype(\n",
    "    {'Video ID':int,\n",
    "     'Start frame(sound)':float,\n",
    "     'End frame(sound)':float}\n",
    "     )\n",
    "\n",
    "combined_df = video_df_refined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86161d4e-e1ab-4aef-962c-dc4d66218d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = 11\n",
    "for i in range(1, max_columns + 1):\n",
    "    combined_df[f'Violence(Sound) Type{i}'] = None\n",
    "    combined_df[f'Sound type{i}'] = None\n",
    "    combined_df[f'sound_start_frame{i}'] = None\n",
    "    combined_df[f'sound_end_frame{i}'] = None\n",
    "\n",
    "combined_df.sort_values(by=['Video ID', 'Start frame'], inplace=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for sound_idx, sound_row in sound_df_refined.iterrows():\n",
    "    s_video_id = sound_row['Video ID']\n",
    "    s_type = sound_row['Violence(Sound) Type']\n",
    "    s_start = sound_row['Start frame(sound)']\n",
    "    s_end = sound_row['End frame(sound)']\n",
    "    s_label = sound_row['sound_label']\n",
    "\n",
    "    matches = combined_df[\n",
    "        (combined_df['Video ID'] == s_video_id) &\n",
    "        (combined_df['Start frame'] <= s_start) &\n",
    "        (combined_df['End frame'] >= s_start)\n",
    "    ]\n",
    "\n",
    "    if matches.empty:\n",
    "        continue\n",
    "\n",
    "    for match_idx in matches.index:\n",
    "        for ix in range(1, max_columns + 1):\n",
    "            if pd.isna(combined_df.at[match_idx, f'Violence(Sound) Type{ix}']):\n",
    "                combined_df.at[match_idx, f'Violence(Sound) Type{ix}'] = s_type\n",
    "                combined_df.at[match_idx, f'Sound type{ix}'] = s_label\n",
    "                combined_df.at[match_idx, f'sound_start_frame{ix}'] = s_start\n",
    "                fill_end = min(s_end, combined_df.at[match_idx, 'End frame'])\n",
    "                combined_df.at[match_idx, f'sound_end_frame{ix}'] = fill_end\n",
    "                break\n",
    "\n",
    "        if s_end > combined_df.at[match_idx, 'End frame']:\n",
    "            remaining_start = combined_df.at[match_idx, 'End frame'] + 1\n",
    "\n",
    "            while remaining_start <= s_end:\n",
    "                next_matches = combined_df[\n",
    "                    (combined_df['Video ID'] == s_video_id) &\n",
    "                    (combined_df['Start frame'] <= remaining_start) &\n",
    "                    (combined_df['End frame'] >= remaining_start)\n",
    "                ]\n",
    "\n",
    "                if next_matches.empty:\n",
    "                    break\n",
    "\n",
    "                for next_idx in next_matches.index:\n",
    "                    segment_end = combined_df.at[next_idx, 'End frame']\n",
    "\n",
    "                    for next_ix in range(1, max_columns + 1):\n",
    "                        if pd.isna(combined_df.at[next_idx, f'Violence(Sound) Type{next_ix}']):\n",
    "                            combined_df.at[next_idx, f'Violence(Sound) Type{next_ix}'] = s_type\n",
    "                            combined_df.at[next_idx, f'Sound type{next_ix}'] = s_label\n",
    "                            combined_df.at[next_idx, f'sound_start_frame{next_ix}'] = remaining_start\n",
    "                            combined_df.at[next_idx, f'sound_end_frame{next_ix}'] = min(s_end, segment_end)\n",
    "                            remaining_start = segment_end + 1\n",
    "                            break\n",
    "                    break  # always move to next row after a fill\n",
    "        break  # only one initial match per sound_row\n",
    "\n",
    "for col in combined_df.columns:\n",
    "    if 'frame' in col:\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: '{:.0f}'.format(x) if pd.notna(x) else '')\n",
    "\n",
    "output_path = os.path.join(\"combined_sound_frame_annotations.xlsx\")\n",
    "combined_df.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3349c-06af-4235-b4ae-97f5e3beb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = 11\n",
    "missing_annotations = []\n",
    "\n",
    "for sound_idx, sound_row in sound_df_refined.iterrows():\n",
    "    s_video_id = sound_row['Video ID']\n",
    "    s_start = round(sound_row['Start frame(sound)'])\n",
    "    s_end = round(sound_row['End frame(sound)'])\n",
    "\n",
    "    # Get all relevant rows in combined_df with same Video ID\n",
    "    video_segments = combined_df[combined_df['Video ID'] == s_video_id]\n",
    "\n",
    "    # Create list of all annotated sound ranges\n",
    "    annotated_ranges = []\n",
    "    for idx, seg in combined_df.iterrows():\n",
    "        for i in range(1, 12):\n",
    "            start_col = f'sound_start_frame{i}'\n",
    "            end_col = f'sound_end_frame{i}'\n",
    "    \n",
    "            start_val = seg[start_col]\n",
    "            end_val = seg[end_col]\n",
    "    \n",
    "            if (\n",
    "                pd.notna(start_val) and pd.notna(end_val)\n",
    "                and str(start_val).strip() != '' and str(end_val).strip() != ''\n",
    "            ):\n",
    "                annotated_ranges.append((int(float(start_val)), int(float(end_val))))\n",
    "\n",
    "\n",
    "    # Sort and merge overlapping or adjacent ranges\n",
    "    annotated_ranges.sort()\n",
    "    merged = []\n",
    "    for start, end in annotated_ranges:\n",
    "        if not merged or start > merged[-1][1] + 1:\n",
    "            merged.append([start, end])\n",
    "        else:\n",
    "            merged[-1][1] = max(merged[-1][1], end)\n",
    "\n",
    "    # Check if any merged range fully covers s_start to s_end\n",
    "    fully_covered = any(start <= s_start and end >= s_end for start, end in merged)\n",
    "\n",
    "    if not fully_covered:\n",
    "        missing_annotations.append((s_video_id, s_start, s_end))\n",
    "\n",
    "\n",
    "if missing_annotations:\n",
    "    print(\"Missing or incomplete annotations:\")\n",
    "    for vid, s, e in missing_annotations:\n",
    "        print(f\"- Video ID: {vid}, Sound Frame: {s} to {e}\")\n",
    "else:\n",
    "    print(\"All sound annotations are fully covered.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1RR7frz5GFQNXQhyDqi89puOXupcDS90c","authorship_tag":"ABX9TyMp6u2MMt5cfzPwquUJwalT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2_Cj0iFSqZc","executionInfo":{"status":"ok","timestamp":1755449521896,"user_tz":-60,"elapsed":26561,"user":{"displayName":"Taejin Kim","userId":"03444209368555110847"}},"outputId":"565c02f5-ca4b-4fe7-ca3c-62fadfbf0e4f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 147MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved GradCAMs for FN 169_10\n","Saved GradCAMs for FP 10_1\n","Saved GradCAMs for TN 102_3\n","Saved GradCAMs for TP 133_1\n"]}],"source":["import os, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.transforms import Resize\n","\n","# ========= PATHS =========\n","NPY_DIR   = \"/content/drive/MyDrive/Colab Notebooks/Projects/npy_segments_unimodal\"\n","CKPT_PATH = \"/content/drive/MyDrive/Colab Notebooks/Results/Unfrozen_randomseed/CUENET/cuenet_best_10.pt\"\n","SAVE_DIR  = \"/content/drive/MyDrive/Colab Notebooks/Results/Interpretability/Again(GradCam)/CUE-NET\"\n","\n","IMG_SIZE  = (224,224)\n","DEVICE    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","# ========= SEGMENTS TO TEST =========\n","SEGMENTS = {\n","    \"FN\": (\"169_10\", [0, 20, 40, 60]),\n","    \"FP\": (\"10_1\",   [0, 10, 30, 50]),\n","    \"TN\": (\"102_3\",  [0, 15, 35, 55]),\n","    \"TP\": (\"133_1\",  [0, 25, 45, 65]),\n","}\n","\n","# ========= MODEL =========\n","class CUE_NET(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # ResNet backbone\n","        self.cnn = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n","        self.cnn.fc = nn.Identity()\n","        # GRU head\n","        self.gru = nn.GRU(2048, 256, batch_first=True, bidirectional=True)\n","        self.fc  = nn.Linear(512, 1)\n","    def forward(self, x):  # [B,T,C,H,W]\n","        B,T,C,H,W = x.shape\n","        x = x.view(B*T,C,H,W)\n","        feats = self.cnn(x)             # [B*T,2048]\n","        feats = feats.view(B,T,-1)      # [B,T,2048]\n","        out, _ = self.gru(feats)\n","        out = out[:,-1]                 # last timestep\n","        return torch.sigmoid(self.fc(out)), feats\n","\n","# ========= GRAD-CAM HOOK =========\n","class GradCAM:\n","    def __init__(self, model, target_layer):\n","        self.model = model\n","        self.target_layer = target_layer\n","        self.gradients = None\n","        self.activations = None\n","        self.hook()\n","    def hook(self):\n","        def fwd_hook(module, inp, out):\n","            self.activations = out.detach()\n","        def bwd_hook(module, grad_in, grad_out):\n","            self.gradients = grad_out[0].detach()\n","        self.target_layer.register_forward_hook(fwd_hook)\n","        self.target_layer.register_full_backward_hook(bwd_hook)\n","    def __call__(self, x):\n","        self.model.zero_grad()\n","        feats = self.model.cnn(x)   # only backbone, bypass GRU\n","        score = feats.mean()\n","        score.backward(torch.ones_like(score))\n","        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n","        cam = torch.relu((weights * self.activations).sum(dim=1, keepdim=True))\n","        cam = torch.nn.functional.interpolate(cam, size=IMG_SIZE, mode=\"bilinear\", align_corners=False)\n","        cam = cam.squeeze().cpu().numpy()\n","        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n","        return cam\n","\n","# ========= HELPERS =========\n","def load_segment(seg_id, frame_indices):\n","    arr = np.load(os.path.join(NPY_DIR, f\"{seg_id}.npy\"))  # [T,H,W,C]\n","    frames = []\n","    for idx in frame_indices:\n","        f = arr[idx]\n","        if f.ndim == 2:  # grayscale → RGB\n","            f = np.stack([f]*3, axis=-1)\n","        t = torch.from_numpy(f).permute(2,0,1).float()/255.0\n","        t = Resize(IMG_SIZE)(t)\n","        frames.append(t)\n","    return torch.stack(frames)  # [T,C,H,W]\n","\n","def overlay_and_save(img_chw, cam, save_path):\n","    img = img_chw.permute(1,2,0).cpu().numpy().clip(0,1)\n","    heatmap = plt.cm.jet(cam)[...,:3]\n","    vis = (0.5*img + 0.5*heatmap).clip(0,1)\n","    plt.imsave(save_path, vis)\n","\n","# ========= MAIN =========\n","if __name__ == \"__main__\":\n","    model = CUE_NET().to(DEVICE)\n","\n","    # === Load checkpoint and rename keys (backbone.* -> cnn.*) ===\n","    state_dict = torch.load(CKPT_PATH, map_location=DEVICE)\n","    new_state_dict = {}\n","    for k, v in state_dict.items():\n","        if k.startswith(\"backbone.\"):\n","            new_k = k.replace(\"backbone.\", \"cnn.\")\n","        else:\n","            new_k = k\n","        new_state_dict[new_k] = v\n","\n","    # load with relaxed matching\n","    model.load_state_dict(new_state_dict, strict=False)\n","\n","    model.eval()\n","\n","    # target layer for GradCAM (last conv block of ResNet50)\n","    target_layer = model.cnn.layer4[-1].conv3\n","    cam_gen = GradCAM(model, target_layer)\n","\n","    for cat,(seg_id,frame_idx_list) in SEGMENTS.items():\n","        frames = load_segment(seg_id, frame_idx_list).to(DEVICE)  # [T,C,H,W]\n","        for i,frame in enumerate(frames):\n","            frame_in = frame.unsqueeze(0).to(DEVICE)  # [1,C,H,W]\n","            cam = cam_gen(frame_in)\n","            overlay_and_save(frame, cam, os.path.join(SAVE_DIR, f\"{cat}_{seg_id}_f{i}.png\"))\n","        print(f\"Saved GradCAMs for {cat} {seg_id}\")\n"]}]}